{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zealand', 0.9207795858383179), ('australian', 0.8780613541603088), ('britain', 0.8478989005088806), ('africa', 0.8332696557044983), ('england', 0.8085248470306396), ('united', 0.8037459254264832), ('canada', 0.7994687557220459), ('south', 0.7845566868782043), ('scotland', 0.7658649682998657), ('wales', 0.7653420567512512)]\n",
      "0.886033768342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\"\"\"\n",
    "word2vec embeddings start with a line with the number of lines (tokens?) and \n",
    "the number of dimensions of the file. This allows gensim to allocate memory \n",
    "accordingly for querying the model. Larger dimensions mean larger memory is \n",
    "held captive. Accordingly, this line has to be inserted into the GloVe \n",
    "embeddings file.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "from sys import platform\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "def prepend_line(infile, outfile, line):\n",
    "\t\"\"\" \n",
    "\tFunction use to prepend lines using bash utilities in Linux. \n",
    "\t(source: http://stackoverflow.com/a/10850588/610569)\n",
    "\t\"\"\"\n",
    "\twith open(infile, 'r', encoding='utf8') as old:\n",
    "\t\twith open(outfile, 'w', encoding='utf8') as new:\n",
    "\t\t\tnew.write(str(line) + \"\\n\")\n",
    "\t\t\tshutil.copyfileobj(old, new)\n",
    "\n",
    "def prepend_slow(infile, outfile, line):\n",
    "\t\"\"\"\n",
    "\tSlower way to prepend the line by re-creating the inputfile.\n",
    "\t\"\"\"\n",
    "\twith open(infile, 'r', encoding='utf8') as fin:\n",
    "\t\twith open(outfile, 'w', encoding='utf8') as fout:\n",
    "\t\t\tfout.write(line + \"\\n\")\n",
    "\t\t\tfor line in fin:\n",
    "\t\t\t\tfout.write(line)\n",
    "\n",
    "def checksum(filename):\n",
    "\t\"\"\"\n",
    "\tThis is to verify the file checksum is the same as the glove files we use to\n",
    "\tpre-computed the no. of lines in the glove file(s).\n",
    "\t\"\"\"\n",
    "\tBLOCKSIZE = 65536\n",
    "\thasher = hashlib.md5()\n",
    "\twith open(filename, 'rb') as afile:\n",
    "\t\tbuf = afile.read(BLOCKSIZE)\n",
    "\t\twhile len(buf) > 0:\n",
    "\t\t\thasher.update(buf)\n",
    "\t\t\tbuf = afile.read(BLOCKSIZE)\n",
    "\treturn hasher.hexdigest()\n",
    "\n",
    "# Pre-computed glove files values.\n",
    "pretrain_num_lines = {\"glove.840B.300d.txt\": 2196017, \"glove.42B.300d.txt\":1917494}\n",
    "\n",
    "pretrain_checksum = {\n",
    "\"glove.6B.300d.txt\":\"b78f53fb56ec1ce9edc367d2e6186ba4\",\n",
    "\"glove.twitter.27B.50d.txt\":\"6e8369db39aa3ea5f7cf06c1f3745b06\",\n",
    "\"glove.42B.300d.txt\":\"01fcdb413b93691a7a26180525a12d6e\",\n",
    "\"glove.6B.50d.txt\":\"0fac3659c38a4c0e9432fe603de60b12\",\n",
    "\"glove.6B.100d.txt\":\"dd7f3ad906768166883176d69cc028de\",\n",
    "\"glove.twitter.27B.25d.txt\":\"f38598c6654cba5e6d0cef9bb833bdb1\",\n",
    "\"glove.6B.200d.txt\":\"49fa83e4a287c42c6921f296a458eb80\",\n",
    "\"glove.840B.300d.txt\":\"eec7d467bccfa914726b51aac484d43a\",\n",
    "\"glove.twitter.27B.100d.txt\":\"ccbdddec6b9610196dd2e187635fee63\",\n",
    "\"glove.twitter.27B.200d.txt\":\"e44cdc3e10806b5137055eeb08850569\",\n",
    "}\n",
    "\n",
    "def check_num_lines_in_glove(filename, check_checksum=False):\n",
    "\tif check_checksum:\n",
    "\t\tassert checksum(filename) == pretrain_checksum[filename]\n",
    "\tif filename.startswith('glove.6B.'):\n",
    "\t\treturn 400000\n",
    "\telif filename.startswith('glove.twitter.27B.'):\n",
    "\t\treturn 1193514\n",
    "\telse:\n",
    "\t\treturn pretrain_num_lines[filename]\n",
    "\t\n",
    "# Input: GloVe Model File\n",
    "# More models can be downloaded from http://nlp.stanford.edu/projects/glove/\n",
    "glove_file=\"glove.6B.50d.txt\"\n",
    "_, tokens, dimensions, _ = glove_file.split('.')\n",
    "num_lines = check_num_lines_in_glove(glove_file)\n",
    "dims = int(dimensions[:-1])\n",
    "\n",
    "# Output: Gensim Model text format.\n",
    "gensim_file='glove_model.txt'\n",
    "gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
    "\n",
    "# Prepends the line.\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "\tprepend_line(glove_file, gensim_file, gensim_first_line)\n",
    "else:\n",
    "\tprepend_slow(glove_file, gensim_file, gensim_first_line)\n",
    "\n",
    "# Demo: Loads the newly created glove_model.txt into gensim API.\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False) #GloVe Model\n",
    "\n",
    "print (model.most_similar(positive=['australia'], topn=10))\n",
    "print (model.similarity('woman', 'man'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
