{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "116\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d64a9603e041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mcounter2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2vecFileTextList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mcosine_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vecFileTextList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcounter2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vecFileTextList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mrelated_docs_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#first 5 related elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mM:\\masters\\semester 4\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mM:\\masters\\semester 4\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[1;32m    110\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 111\u001b[0;31m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mM:\\masters\\semester 4\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import csv, os, shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "csvfile = open('M:\\masters\\semester 4\\web scraping\\output files\\TopicStats\\Syria.csv', newline='') \n",
    "word2vecFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesWord2Vec\"\n",
    "spamreader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "MPNames = [] #where the MP Names are saved (actual list from syria speeches folder)\n",
    "MPParty =[] #where the MP party will be saved (should have same index as MPNames)\n",
    "CSVStatsMpNames = [] #where the MP Names from the CSV Statistic file are saved\n",
    "CSVStatsMpParty = [] #where the MP Party from the SCV Statistics file are saved\n",
    "word2vecFileTextList = [] #where the TagMe TextFiles are Saved\n",
    "\n",
    "#function that returns the MPs party name and it takes as input the list with all mp names, list with their corresponding parties\n",
    "# as well as the name of the MP we are looking for.\n",
    "def getParty(CSVStatsMpNames, CSVStatsMpParty, name):\n",
    "    for mpnames in CSVStatsMpNames:\n",
    "        index = CSVStatsMpNames.index(mpnames)\n",
    "        if(name.strip() in mpnames.strip()):\n",
    "            mpparty = CSVStatsMpParty[index]\n",
    "            return mpparty\n",
    "\n",
    "for file in os.listdir(word2vecFolderDirectory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(word2vecFolderDirectory,file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    lista = [float(x) for x in fileText.read().split(\" \") if len(x)>2]\n",
    "    word2vecFileTextList.append(lista)\n",
    "        \n",
    "for fileName in os.listdir(word2vecFolderDirectory): #save the names to correspond the texts\n",
    "    NameList = fileName.strip().split(\"_\")\n",
    "    MpName = \"\"\n",
    "    if(len(NameList) >= 2):\n",
    "        MpName = NameList[0] +\" \"+ NameList[1]\n",
    "    else:\n",
    "        MpName = NameList[0]\n",
    "    MPNames.append(MpName)\n",
    "\n",
    "for row in spamreader: #saving mpnames and parties from the statistics file\n",
    "    mpname = row[0].strip()\n",
    "    mpparty = row[1].strip()\n",
    "    if(mpname not in CSVStatsMpNames):\n",
    "        CSVStatsMpNames.append(mpname)\n",
    "        CSVStatsMpParty.append(mpparty)\n",
    "print(len(CSVStatsMpNames))\n",
    "print(len(CSVStatsMpParty))\n",
    "\n",
    "for MP in MPNames: #matchin MPnames from the folder with their parties\n",
    "    index = MPNames.index(MP)\n",
    "    mpparty = getParty(CSVStatsMpNames,CSVStatsMpParty, MP.strip())\n",
    "    MPParty.insert(index, mpparty)\n",
    "    \n",
    "#tfidf = TfidfVectorizer().fit_transform(word2vecFileTextList) no need for tfidf because they are already vectors\n",
    "#cosine_similarities = linear_kernel(tfidf[0:1], tfidf).flatten()\n",
    "#it gets the matrix as an input example, \"[len(TagMeFileTextList)-1:len(TagMeFileTextList)]\" or \"[0:1]\"\n",
    "counter1 = 0\n",
    "counter2 = 1\n",
    "for file in word2vecFileTextList:\n",
    "    cosine_similarities = cosine_similarity(word2vecFileTextList[counter1:counter2], word2vecFileTextList).flatten() \n",
    "    print(cosine_similarities)\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-6:-1] #first 5 related elements\n",
    "    print(related_docs_indices)\n",
    "    RelatedDocsParties = []\n",
    "    RelatedDocMps =[]\n",
    "    for doc in related_docs_indices:\n",
    "        docparty = MPParty[doc]\n",
    "        docMp = MPNames[doc]\n",
    "        RelatedDocMps.append(docMp)\n",
    "        RelatedDocsParties.append(docparty)\n",
    "    \n",
    "    counter1 = counter1 + 1 #counters are used to loop each file to compare it with all the others\n",
    "    counter2 = counter2 + 1 #counters are used to loop each file to compare it with all the others\n",
    "    \n",
    "    print(\"related doc mps: \", RelatedDocMps)    \n",
    "    print(\"related doc parties: \", RelatedDocsParties)\n",
    "    print(\"related doc indices :\" ,related_docs_indices)\n",
    "    print(len(related_docs_indices))\n",
    "    print(cosine_similarities[related_docs_indices])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
