{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "\n",
    "#sentences = word2vec.Word2Vec.load()#try here to put the courpus of glove\n",
    "gensim_file='M:\\masters\\semester 4\\ProjectData\\Clean.glove.6B\\glove_model_6B_50d.txt'\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False)\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    print (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model[\"bidens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this class is for saving the vectors with their words in a file\n",
    "import gensim, os, time\n",
    "\n",
    "directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "#annotations = [] #have all the entities annotated for a certain text file\n",
    "Word2vecFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesWord2Vec\"\n",
    "\n",
    "\n",
    "gensim_file='M:\\masters\\semester 4\\ProjectData\\Clean.glove.6B\\glove_model_6B_50d.txt'\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False)    #where the model is created\n",
    "    \n",
    "for file in os.listdir(directory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(directory,file)\n",
    "    FileNames.append(file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    FileTextList.append(fileText.read())\n",
    "\n",
    "counter = 0;\n",
    "for file in FileTextList: #takes the text of each file\n",
    "    Word2vecFileDirectory = os.path.join(Word2vecFolderDirectory, FileNames[counter]) #creates the file directory\n",
    "    text_file = open(Word2vecFileDirectory, \"w\", encoding='utf-8')    #creates the file in that directory\n",
    "    split_text = file.split(\"|\") #splits the text into lines based separator \"|\"\n",
    "    split_lines = [] #an array to save the words from the split lines\n",
    "    for text in split_text:\n",
    "        split_lines = text.split(\" \") #array of the split text , that is re-split into an array of words\n",
    "        for word in split_lines: #loops each word in the current line\n",
    "            clean_word = re.sub(r'[^a-zA-Z0-9 ]',r'', word ) #cleans the word\n",
    "            #print (clean_word)\n",
    "            if(clean_word != ''): #check that if the word was actually a saved symbol to ignore it\n",
    "                text_file.write(clean_word.lower()) #used s.lower() to convert the words to lower cases so it can be matched with glove\n",
    "                text_file.write(\" \")\n",
    "                for x in model[clean_word.lower()]: #this is where model[\"word\"] is called to get its vector\n",
    "                    value = str(x)\n",
    "                    text_file.write(value)\n",
    "                    text_file.write(\" \")\n",
    "\n",
    "        split_lines.clear()\n",
    "    text_file.close()\n",
    "    counter = counter + 1 \n",
    "    print(\"Done file\" , Word2vecFileDirectory)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this class is to combine the try and except method incase words were not found in the corpus\n",
    "import gensim, os, time\n",
    "\n",
    "directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "#annotations = [] #have all the entities annotated for a certain text file\n",
    "Word2vecFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesWord2Vec\"\n",
    "\n",
    "\n",
    "gensim_file='M:\\masters\\semester 4\\ProjectData\\Clean.glove.6B\\glove_model_6B_50d.txt'\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False)    #where the model is created\n",
    "    \n",
    "for file in os.listdir(directory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(directory,file)\n",
    "    FileNames.append(file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    FileTextList.append(fileText.read())\n",
    "\n",
    "counter = 0;\n",
    "for file in FileTextList: #takes the text of each file\n",
    "    Word2vecFileDirectory = os.path.join(Word2vecFolderDirectory, FileNames[counter]) #creates the file directory\n",
    "    text_file = open(Word2vecFileDirectory, \"w\", encoding='utf-8')    #creates the file in that directory\n",
    "    split_text = file.split(\"|\") #splits the text into lines based separator \"|\"\n",
    "    split_lines = [] #an array to save the words from the split lines\n",
    "    for text in split_text:\n",
    "        split_lines = text.split(\" \") #array of the split text , that is re-split into an array of words\n",
    "        for word in split_lines: #loops each word in the current line\n",
    "            clean_word = re.sub(r'[^a-zA-Z0-9 ]',r'', word ) #cleans the word\n",
    "            #print (clean_word)\n",
    "            if(clean_word != ''): #check that if the word was actually a saved symbol to ignore it\n",
    "                text_file.write(clean_word.lower()) #used s.lower() to convert the words to lower cases so it can be matched with glove\n",
    "                text_file.write(\" \")\n",
    "                try:\n",
    "                    modelVector = model[clean_word.lower()] #this is where model[\"word\"] is called to get its vector\n",
    "                    for x in modelVector:\n",
    "                        value = str(x)\n",
    "                        text_file.write(value)\n",
    "                        text_file.write(\" \")\n",
    "                except:\n",
    "                    print (\"that word did not exist : \" ,clean_word)\n",
    "                    break\n",
    "\n",
    "        split_lines.clear()\n",
    "    text_file.close()\n",
    "    counter = counter + 1 \n",
    "    print(\"Done file\" , Word2vecFileDirectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this class is to get the average for each document\n",
    "import gensim, os, time\n",
    "\n",
    "directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "#annotations = [] #have all the entities annotated for a certain text file\n",
    "Word2vecFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesWord2Vec\"\n",
    "\n",
    "modelVectorList = [] #list with all the word vectors\n",
    "\n",
    "gensim_file='M:\\masters\\semester 4\\ProjectData\\Clean.glove.6B\\glove_model_6B_50d.txt'\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False)    #where the model is created\n",
    "    \n",
    "for file in os.listdir(directory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(directory,file)\n",
    "    FileNames.append(file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    FileTextList.append(fileText.read())\n",
    "\n",
    "counter = 0;\n",
    "for file in FileTextList: #takes the text of each file\n",
    "    Word2vecFileDirectory = os.path.join(Word2vecFolderDirectory, FileNames[counter]) #creates the file directory\n",
    "    text_file = open(Word2vecFileDirectory, \"w\", encoding='utf-8')    #creates the file in that directory\n",
    "    split_text = file.split(\"|\") #splits the text into lines based separator \"|\"\n",
    "    split_lines = [] #an array to save the words from the split lines\n",
    "    for text in split_text:\n",
    "        split_lines = text.split(\" \") #array of the split text , that is re-split into an array of words\n",
    "        for word in split_lines: #loops each word in the current line\n",
    "            clean_word = re.sub(r'[^a-zA-Z0-9 ]',r'', word ) #cleans the word\n",
    "            #print (clean_word)\n",
    "            if(clean_word != ''): #check that if the word was actually a saved symbol to ignore it\n",
    "                try:\n",
    "                modelVector = model[clean_word.lower()] #this is where model[\"word\"] is called to get its vector\n",
    "                modelVectorList.append(modelVector) #adds the vector array of the word to the list\n",
    "            except:\n",
    "                print (\"that word did not exist : \" ,clean_word)\n",
    "                break\n",
    "\n",
    "        split_lines.clear()\n",
    "        \n",
    "    average = [float(sum(col))/len(col) for col in zip(*modelVectorList)] #returns a LIST with avergaes the vector array for the file \n",
    "    \n",
    "    for avg in average:\n",
    "        avgtxt = str(avg) + \" \"\n",
    "        text_file.write(avgtxt) \n",
    "\n",
    "    text_file.close()\n",
    "    counter = counter + 1 \n",
    "    modelVectorList.clear() #clears the list to be used by the next file\n",
    "    \n",
    "    print(\"Done file\" , Word2vecFileDirectory)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
