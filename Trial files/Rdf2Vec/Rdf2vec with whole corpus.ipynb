{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports the rdf2vec model\n",
    "import gensim, os, time, re\n",
    "from gensim.models import word2vec\n",
    "directory = \"M:\\\\masters\\\\semester 4\\\\ProjectData\\\\2016_2015\" #read a certain text\n",
    "rdf2vec='M:\\\\masters\\\\semester 4\\\\ProjectData\\\\rdf2vec\\\\rdf2vec'\n",
    "model= word2vec.Word2Vec.load(rdf2vec)\n",
    "print(\"loaded the rdf2vec model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this class is to get the average for each document\n",
    "directory = \"M:\\\\masters\\\\semester 4\\\\ProjectData\\\\2016_2015\" #read a certain text\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    TagMeDirectory = folder +\"\\\\\"+\"tagMe\"\n",
    "    Topicfolderpath = os.path.join(directory, TagMeDirectory)\n",
    "    #print (\"topic folder path \", Topicfolderpath)\n",
    "    #directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "    FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "    FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "    #annotations = [] #have all the entities annotated for a certain text file\n",
    "    rdf2vecFolder = folder +\"\\\\\"+\"rdf2vec\"\n",
    "    rdf2vecFolderDirectory = os.path.join(directory, rdf2vecFolder)\n",
    "    #print (\"word2vec path  \", word2vecFolderDirectory)\n",
    "\n",
    "    modelVectorList = [] #list with all the word vectors\n",
    "\n",
    "    for file in os.listdir(Topicfolderpath): #save the text from the syria files\n",
    "        filedirectorylink = os.path.join(Topicfolderpath,file)\n",
    "        FileNames.append(file)\n",
    "        fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "        FileTextList.append(fileText.read())\n",
    "\n",
    "    counter = 0;\n",
    "    for file in FileTextList: #takes the text of each file\n",
    "        rdf2vecFileDirectory = os.path.join(rdf2vecFolderDirectory, FileNames[counter]) #creates the file directory\n",
    "        text_file = open(rdf2vecFileDirectory, \"w\", encoding='utf-8')    #creates the file in that directory\n",
    "        split_text = file.split(\"|\") #splits the text into lines based separator \"|\"\n",
    "        for text in split_text:\n",
    "            cleanText = text.strip()\n",
    "            if(len(cleanText) > 2): #to remove the spaces from being recognized as entities\n",
    "                textwithunderscore = cleanText.replace(\" \", \"_\")\n",
    "                addRdf = 'dbr:' + textwithunderscore+ \"\"\n",
    "                try:\n",
    "                    modelVector = model[addRdf] #this is where model[\"word\"] is called to get its vector\n",
    "                    modelVectorList.append(modelVector) #adds the vector array of the word to the list\n",
    "                except:\n",
    "                    print (\"that word did not exist : \" ,addRdf)\n",
    "                    break\n",
    "\n",
    "        average = [float(sum(col))/len(col) for col in zip(*modelVectorList)] #returns a LIST with avergaes the vector array for the file \n",
    "\n",
    "        for avg in average:\n",
    "            avgtxt = str(avg) + \" \"\n",
    "            text_file.write(avgtxt) \n",
    "\n",
    "        text_file.close()\n",
    "        counter = counter + 1 \n",
    "        modelVectorList.clear() #clears the list to be used by the next file\n",
    "        print(\"Done file\" , rdf2vecFileDirectory)\n",
    "\n",
    "print (\"done with rdf2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
