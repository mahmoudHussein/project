{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this class is to get the average for each document\n",
    "import tagme, os, time, re\n",
    "directory = \"M:\\\\masters\\\\semester 4\\\\ProjectData\\\\2016_2015\" #read a certain text\n",
    "tagme.GCUBE_TOKEN = \"bd8f93c8-dcec-4c5b-a348-3d3dfbcfec62-843339462\"\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    SpeechesDirectory = folder +\"\\\\\"+\"speeches\"\n",
    "    Topicfolderpath = os.path.join(directory, SpeechesDirectory)\n",
    "    #print (\"topic folder path \", Topicfolderpath)\n",
    "    #directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "    FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "    FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "    #annotations = [] #have all the entities annotated for a certain text file\n",
    "    TagMeFolder = folder +\"\\\\\"+\"tagMe\"\n",
    "    TagMeFolderDirectory = os.path.join(directory, TagMeFolder)\n",
    "    #print (\"word2vec path  \", word2vecFolderDirectory)\n",
    "\n",
    "    annotations = [] #list with all the annotations\n",
    "\n",
    "    for file in os.listdir(Topicfolderpath): #save the text from the syria files\n",
    "        filedirectorylink = os.path.join(Topicfolderpath,file)\n",
    "        FileNames.append(file)\n",
    "        fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "        FileTextList.append(fileText.read())\n",
    "\n",
    "    counter = 0 #counter to get the name of the files from the array to use as the new file name in the tag me folder    \n",
    "    for syriaSpeech in FileTextList: #take each speech from the FileTextList then split each line of it at every \"|\"\n",
    "        splitFileText = syriaSpeech.split(\"/n\") #split everyline on its own and save it in a list\n",
    "    #loops each line and in the file and annotate it then add the retrieved entities to the annotations list\n",
    "        for line in splitFileText:\n",
    "            #print(\"new line here: \" , line)\n",
    "            test_Large_text = tagme.annotate(line)\n",
    "        # Print annotations with a score higher than 0.1\n",
    "            for ann in test_Large_text.get_annotations(0.23):\n",
    "                annotations.append(ann.entity_title)\n",
    "                #print(\"entity : \", ann.entity_title, \" , \",\"mention : \", ann.mention, \" , \",\"score : \", ann.score)\n",
    "        #print(annotations)\n",
    "\n",
    "        TagMeFileDirectory = os.path.join(TagMeFolderDirectory, FileNames[counter])\n",
    "        text_file = open(TagMeFileDirectory, \"w\", encoding='utf-8')    \n",
    "        for a in annotations:\n",
    "            inputText = a + \" | \"\n",
    "            text_file.write(inputText)    \n",
    "        text_file.close()\n",
    "        print(\"Done file\" , TagMeFileDirectory)\n",
    "        #print(\"all annotations: \", annotations, \"counter :\" , counter)\n",
    "        annotations.clear() #emptys the annotations array after it has been written to the file\n",
    "        counter = counter + 1 \n",
    "        time.sleep( 2 ) #sleeps the thread 2 seconds so it won't get banned from excessive requests\n",
    "    #print(\"all annotations: \", annotations)\n",
    "\n",
    "print(\"done with all files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
