{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tagme, os, time\n",
    "\n",
    "tagme.GCUBE_TOKEN = \"bd8f93c8-dcec-4c5b-a348-3d3dfbcfec62-843339462\"\n",
    "\n",
    "directory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeeches\" #read a certain text\n",
    "FileTextList = [] #where the text inside each file is saved, correpondes to the MP name in the MPName list index (actual list from syria speeches folder)\n",
    "FileNames = [] #where the file names would be saved inorder to be used later in the tag me files folder \n",
    "annotations = [] #have all the entities annotated for a certain text file\n",
    "    \n",
    "    \n",
    "for file in os.listdir(directory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(directory,file)\n",
    "    FileNames.append(file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    FileTextList.append(fileText.read())\n",
    "    \n",
    "    \n",
    "counter = 0 #counter to get the name of the files from the array to use as the new file name in the tag me folder    \n",
    "for syriaSpeech in FileTextList: #take each speech from the FileTextList then split each line of it at every \"|\"\n",
    "    splitFileText = syriaSpeech.split(\"/n\") #split everyline on its own and save it in a list\n",
    "#loops each line and in the file and annotate it then add the retrieved entities to the annotations list\n",
    "    for line in splitFileText:\n",
    "        #print(\"new line here: \" , line)\n",
    "        test_Large_text = tagme.annotate(line)\n",
    "    # Print annotations with a score higher than 0.1\n",
    "        for ann in test_Large_text.get_annotations(0.23):\n",
    "            annotations.append(ann.entity_title)\n",
    "            #print(\"entity : \", ann.entity_title, \" , \",\"mention : \", ann.mention, \" , \",\"score : \", ann.score)\n",
    "    #print(annotations)\n",
    "\n",
    "    TagMeFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesTagMe\"\n",
    "    TagMeFileDirectory = os.path.join(TagMeFolderDirectory, FileNames[counter])\n",
    "    text_file = open(TagMeFileDirectory, \"w\", encoding='utf-8')    \n",
    "    for a in annotations:\n",
    "        inputText = a + \" | \"\n",
    "        text_file.write(inputText)    \n",
    "    text_file.close()\n",
    "    print(\"Done file\" , TagMeFileDirectory)\n",
    "    #print(\"all annotations: \", annotations, \"counter :\" , counter)\n",
    "    annotations.clear() #emptys the annotations array after it has been written to the file\n",
    "    counter = counter + 1 \n",
    "    time.sleep( 2 ) #sleeps the thread 2 seconds so it won't get banned from excessive requests\n",
    "#print(\"all annotations: \", annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "116\n",
      "[ 1.          0.60394709  0.57576742  0.0277568   0.55625158  0.55678493\n",
      "  0.43427986  0.19623446  0.43023815  0.43091271  0.01918157  0.49112752\n",
      "  0.53253838  0.6120939   0.29199006  0.45072054  0.51248292  0.0510872\n",
      "  0.04188413  0.52476386  0.43112977  0.56993998  0.54495451  0.10708998\n",
      "  0.34812609  0.02861182  0.09717292  0.39310902  0.421872    0.45165357\n",
      "  0.38049954  0.39399521  0.54112187  0.54721334  0.57181275  0.04041438\n",
      "  0.20996366  0.18442362  0.0637471   0.04914753  0.21157152  0.55340155\n",
      "  0.05962619  0.25801291  0.56362598  0.62289209  0.04279696  0.59506399\n",
      "  0.02637499  0.48723858  0.15463668  0.49987369  0.19270162  0.53592872\n",
      "  0.18250223  0.56863907  0.05678732  0.50440214  0.31841015  0.30486224\n",
      "  0.38060909  0.14693648  0.          0.6120939   0.54079487  0.0551545\n",
      "  0.05809274  0.52751176  0.14155245  0.09170466  0.51747749  0.4980734\n",
      "  0.36478874  0.53651423  0.40736549  0.443132    0.08467638  0.58132953\n",
      "  0.01433976  0.41396325  0.32566842  0.28447401  0.20455316  0.6120939\n",
      "  0.38481867  0.07299266  0.54092185  0.44935857  0.00963356  0.02503146\n",
      "  0.60714239  0.03482041  0.36103237  0.01745667  0.2840816   0.34880188\n",
      "  0.21339907  0.47630756  0.55882944  0.5189942   0.15699878  0.33093723\n",
      "  0.47030743  0.59976151  0.05190986  0.6001793   0.22999766  0.26312274\n",
      "  0.03741108  0.44031217  0.5717993   0.41572086  0.40113317  0.13940897\n",
      "  0.52394731  0.47361138  0.06989955  0.22963242  0.47434574  0.04279696\n",
      "  0.53169735  0.55949557  0.58636972  0.42682457  0.39747377  0.54112187\n",
      "  0.22999766  0.21339907  0.04914753  0.03741108  0.07299266  0.15463668\n",
      "  0.38481867  0.54721334  0.11395505  0.09785802  0.02176624  0.20784165\n",
      "  0.          0.05158406  0.35082501  0.24564783  0.60394709  1.          0.9444717\n",
      "  0.02287647  0.87583165  0.91479848  0.67824684  0.2727622   0.69051691\n",
      "  0.68519955  0.          0.76644552  0.85844743  0.98669027  0.42764586\n",
      "  0.73088432  0.82794187  0.05350406  0.07808068  0.83988307  0.69002197\n",
      "  0.90614202  0.85083314  0.13124589  0.54143395  0.04090917  0.16037893\n",
      "  0.5706968   0.60943991  0.73390166  0.62995116  0.6308909   0.83233688\n",
      "  0.8758134   0.91519452  0.04957331  0.31451831  0.26638583  0.0595931\n",
      "  0.01582479  0.33550846  0.88695433  0.02600584  0.4104886   0.8491177\n",
      "  0.96877233  0.07232501  0.92653693  0.04353057  0.75043138  0.20047385\n",
      "  0.79858224  0.31926497  0.85133253  0.24596459  0.88812794  0.06544613\n",
      "  0.79856802  0.51327451  0.47359958  0.61583545  0.22908709  0.\n",
      "  0.98669027  0.85888095  0.07477557  0.04237067  0.8180779   0.22124352\n",
      "  0.07765442  0.76337935  0.81811892  0.59716198  0.83007171  0.66660128\n",
      "  0.75346661  0.13234742  0.98800249  0.02366703  0.67039332  0.52591177\n",
      "  0.43673621  0.30325273  0.98669027  0.49533259  0.          0.84905056\n",
      "  0.72584221  0.0158997   0.03342893  0.96024102  0.0639872   0.57758879\n",
      "  0.05961455  0.4846106   0.54078017  0.31480488  0.66527986  0.91804246\n",
      "  0.81791741  0.26907693  0.49206325  0.70020879  0.92497775  0.08567456\n",
      "  0.90214734  0.30668888  0.37505788  0.          0.6974816   0.87976508\n",
      "  0.66241403  0.65914804  0.18326842  0.86717835  0.75310038  0.05382377\n",
      "  0.11662924  0.73352401  0.07232501  0.84461092  0.92689191  0.9452231\n",
      "  0.68869558  0.64072442  0.83233688  0.30668888  0.31480488  0.01582479\n",
      "  0.          0.          0.20047385  0.49533259  0.8758134   0.05895999\n",
      "  0.17523262  0.03592406  0.23115465  0.          0.05673732  0.55857692\n",
      "  0.34777774]\n",
      "[  0 143 219 205 225]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f83680519011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mRelatedDocMps\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelated_docs_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdocparty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMPParty\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdocMp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMPNames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mRelatedDocMps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocMp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv, os, shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "csvfile = open('M:\\masters\\semester 4\\web scraping\\output files\\TopicStats\\Syria.csv', newline='') \n",
    "TagMeFolderDirectory = \"M:\\masters\\semester 4\\ProjectData\\SyriaSpeechesTagMe\"\n",
    "spamreader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "MPNames = [] #where the MP Names are saved (actual list from syria speeches folder)\n",
    "MPParty =[] #where the MP party will be saved (should have same index as MPNames)\n",
    "CSVStatsMpNames = [] #where the MP Names from the CSV Statistic file are saved\n",
    "CSVStatsMpParty = [] #where the MP Party from the SCV Statistics file are saved\n",
    "TagMeFileTextList = [] #where the TagMe TextFiles are Saved\n",
    "\n",
    "#function that returns the MPs party name and it takes as input the list with all mp names, list with their corresponding parties\n",
    "# as well as the name of the MP we are looking for.\n",
    "def getParty(CSVStatsMpNames, CSVStatsMpParty, name):\n",
    "    for mpnames in CSVStatsMpNames:\n",
    "        index = CSVStatsMpNames.index(mpnames)\n",
    "        if(name.strip() in mpnames.strip()):\n",
    "            mpparty = CSVStatsMpParty[index]\n",
    "            return mpparty\n",
    "\n",
    "for file in os.listdir(TagMeFolderDirectory): #save the text from the syria files\n",
    "    filedirectorylink = os.path.join(TagMeFolderDirectory,file)\n",
    "    fileText = open(filedirectorylink, encoding=\"utf8\")\n",
    "    TagMeFileTextList.append(fileText.read())\n",
    "        \n",
    "for fileName in os.listdir(TagMeFolderDirectory): #save the names to correspond the texts\n",
    "    NameList = fileName.strip().split(\"_\")\n",
    "    MpName = \"\"\n",
    "    if(len(NameList) >= 2):\n",
    "        MpName = NameList[0] +\" \"+ NameList[1]\n",
    "    else:\n",
    "        MpName = NameList[0]\n",
    "    MPNames.append(MpName)\n",
    "\n",
    "for row in spamreader: #saving mpnames and parties from the statistics file\n",
    "    mpname = row[0].strip()\n",
    "    mpparty = row[1].strip()\n",
    "    if(mpname not in CSVStatsMpNames):\n",
    "        CSVStatsMpNames.append(mpname)\n",
    "        CSVStatsMpParty.append(mpparty)\n",
    "print(len(CSVStatsMpNames))\n",
    "print(len(CSVStatsMpParty))\n",
    "\n",
    "for MP in MPNames: #matchin MPnames from the folder with their parties\n",
    "    index = MPNames.index(MP)\n",
    "    mpparty = getParty(CSVStatsMpNames,CSVStatsMpParty, MP.strip())\n",
    "    MPParty.insert(index, mpparty)\n",
    "    \n",
    "tfidf = TfidfVectorizer().fit_transform(TagMeFileTextList)\n",
    "#cosine_similarities = linear_kernel(tfidf[0:1], tfidf).flatten()\n",
    "#it gets the matrix as an input example, \"[len(TagMeFileTextList)-1:len(TagMeFileTextList)]\" or \"[0:1]\"\n",
    "counter1 = 0\n",
    "counter2 = 1\n",
    "for file in TagMeFileTextList:\n",
    "    cosine_similarities = cosine_similarity(tfidf[counter1:counter2], tfidf).flatten() \n",
    "    print(cosine_similarities)\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-6:-1] #first 5 related elements\n",
    "    print(related_docs_indices)\n",
    "    RelatedDocsParties = []\n",
    "    RelatedDocMps =[]\n",
    "    for doc in related_docs_indices:\n",
    "        docparty = MPParty[doc]\n",
    "        docMp = MPNames[doc]\n",
    "        RelatedDocMps.append(docMp)\n",
    "        RelatedDocsParties.append(docparty)\n",
    "    \n",
    "    counter1 = counter1 + 1 #counters are used to loop each file to compare it with all the others\n",
    "    counter2 = counter2 + 1 #counters are used to loop each file to compare it with all the others\n",
    "    \n",
    "    print(\"related doc mps: \", RelatedDocMps)    \n",
    "    print(\"related doc parties: \", RelatedDocsParties)\n",
    "    print(\"related doc indices :\" ,related_docs_indices)\n",
    "    print(len(related_docs_indices))\n",
    "    print(cosine_similarities[related_docs_indices])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
